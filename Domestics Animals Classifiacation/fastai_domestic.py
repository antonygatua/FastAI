# -*- coding: utf-8 -*-
"""fastai_domestic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ezezNv_BYkB89W-sVyhe4eO6BCQjuopj
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
# import the fastai library
from fastai.vision import *
from fastai.metrics import accuracy, error_rate

# create an empty list of domestic animals 
domestic_animals = ["cat","dog","goat", "sheep", "cow", "chicken", "dove", "pig", "duck", "turkey", "camel", "donkey", "horse"]

# create a folder to store the data and path to the folder
path = Path('data/')

#create an empty list to store the images
folder = []

# loop through the domestic animals
for i in domestic_animals:
  # assign path to the animals in the list
  dest = path/i
  # create directories/folders to store the images
  dest.mkdir(parents=True, exist_ok=True)
  # add to the empty list
  folder.append(dest)

# create an empty list to store the csv files
csv = []
for j in domestic_animals:
  files = j+'.csv'
  csv.append(files)

folder

csv

# download the images and store them in folders created
m = 0

while m < len(csv):
  # using the download_images function to download 300 images for each category
  download_images(path/csv[m], folder[m], max_pics=300)
  m += 1

# def download_images(classes):
  
#   path = Path('data/')

#   folder = []

#   for i in classes:
#     dest = path/i
#     dest.mkdir(parents=True, exist_ok = True)
#     folder.append(dest)


#   csv = []

#   for j in classes:
#     files = j+'.csv'
#     csv.append(files)


#   m = 0

#   while m < len(csv):
#     download_images(path/csv[m], folder[m], max_pics=300)
#     m += 1 


#   return path.ls()

# verify the classes that we have to ensure no corrupt images
for c in domestic_animals:
  print(c)
  verify_images(path/c, delete=True, max_size=500)

# visualize the downloaded data
# select a random seed
np.random.seed(42)

# loading the data
data = ImageDataBunch.from_folder(path, train='.', valid_pct=0.3, ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)

# view the classes
data.classes

# view the data
data.show_batch(5, figsize=(12,10))

# create a model and initial training 
# creating a convolutional neural network using create_cnn
learn = create_cnn(data, models.resnet34, metrics=[accuracy, error_rate])

defaults.device = torch.device('cuda') # use the gpu
# train the layers 
learn.fit_one_cycle(5)

#the model architecture
learn.model

# unfreeze to train the whole network 
learn.unfreeze()

# find the perfect learning rate >> Differential learning rate
learn.lr_find

# visualize the learning rates
learn.recorder.plot()

"""* looking for the steepest downward slope """

# train the model using differential learning rates 
learn.fit_one_cycle(4, max_lr=slice(3e-4))

# save the model
learn.save("part1")

"""## Improve the model by cleaning the images"""

# using image cleaner 
from fastai.widgets import *

ds, idxs = DatasetFormatter().from_toplosses(learn)
ImageCleaner(ds, idxs, path)

# results are saved as cleaned.csv 
df = pd.read_csv(path/'cleaned.csv', header='infer')
df.head()

db = (ImageList.from_df(df,path)
                   .random_split_by_pct(0.2)
                   .label_from_df()
                   .transform(get_transforms(), size=224)
                   .databunch(bs=8)).normalize(imagenet_stats)

# difference after deleting the images
print(data.classes, data.c, len(data.train_ds), len(data.valid_ds))
print(db.classes, db.c, len(db.train_ds), len(db.valid_ds))

# view a batch from db
db.show_batch()

# load the saved model
learn.load("part1")

# replace the data
learn.data = db

learn.freeze()

learn.fit_one_cycle(4)

learn.unfreeze

learn.save('Final')

"""## Evaluation"""

# use ClassificationInterpretation 
classif = ClassificationInterpretation.from_learner(learn)

# plot the top losses 
classif.plot_top_losses(9, figsize=(15,15))

# display on confusion matrix
classif.plot_confusion_matrix()

# export the model for deployment
learn.export('/content/model.pkl')

